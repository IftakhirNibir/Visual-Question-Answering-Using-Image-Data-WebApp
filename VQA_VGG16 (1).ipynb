{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyB0yymfReaT"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.layers import GlobalAveragePooling2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqFwBr-qTWbo",
        "outputId": "aa425027-3420-496d-c120-6297474b45fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G10RaRSsRrY1"
      },
      "outputs": [],
      "source": [
        "# Load the JSON files\n",
        "with open('/content/drive/MyDrive/bangla dataset/train_questions_save (1).json', 'r') as f:\n",
        "    train_data = json.load(f)\n",
        "\n",
        "with open('/content/drive/MyDrive/bangla dataset/train_questions_save (1).json', 'r') as f:\n",
        "    test_data = json.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxF7H25QRsXg"
      },
      "outputs": [],
      "source": [
        "# Define image and question data\n",
        "train_image_ids = []\n",
        "train_questions = []\n",
        "train_answers = []\n",
        "test_image_ids = []\n",
        "test_questions = []\n",
        "test_answers = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-mHFaj9RuZK"
      },
      "outputs": [],
      "source": [
        "for key in train_data:\n",
        "    train_image_ids.append(train_data[key]['image_id'])\n",
        "    train_questions.append(train_data[key]['question'])\n",
        "    train_answers.append(train_data[key]['answer'])\n",
        "\n",
        "for key in test_data:\n",
        "    test_image_ids.append(test_data[key]['image_id'])\n",
        "    test_questions.append(test_data[key]['question'])\n",
        "    test_answers.append(test_data[key]['answer'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame from your data\n",
        "train_data = pd.DataFrame({\n",
        "    'Image_ID': train_image_ids,\n",
        "    'Questions': train_questions,\n",
        "    'Answers': train_answers\n",
        "})\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "train_data.to_csv('train_data.csv', index=False)"
      ],
      "metadata": {
        "id": "8PMJLsVp6YNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame from your data\n",
        "test_data = pd.DataFrame({\n",
        "    'Image_ID': test_image_ids,\n",
        "    'Questions': test_questions,\n",
        "    'Answers': test_answers\n",
        "})\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "test_data.to_csv('test_data.csv', index=False)"
      ],
      "metadata": {
        "id": "PhDrA4563CiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XAjW-SvYRwQL"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess images\n",
        "image_dir = '/content/drive/MyDrive/bangla dataset/Images/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCkfG399RyIq"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    img = Image.open(image_path)\n",
        "    img = img.convert('RGB')\n",
        "    img = img.resize((224, 224))\n",
        "    img = img_to_array(img)\n",
        "    img = img / 255.0\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEjVIziQR0Ls"
      },
      "outputs": [],
      "source": [
        "train_images = [preprocess_image(image_dir + image_id + '.png') for image_id in train_image_ids]\n",
        "train_images = np.array(train_images)\n",
        "\n",
        "test_images = [preprocess_image(image_dir + image_id + '.png') for image_id in test_image_ids]\n",
        "test_images = np.array(test_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLY4PMFDR2YD"
      },
      "outputs": [],
      "source": [
        "# Process questions\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_questions)\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqyF9NhbR2Yo"
      },
      "outputs": [],
      "source": [
        "train_question_sequences = tokenizer.texts_to_sequences(train_questions)\n",
        "train_question_sequences = pad_sequences(train_question_sequences, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXn_SyNmR7_U"
      },
      "outputs": [],
      "source": [
        "test_question_sequences = tokenizer.texts_to_sequences(test_questions)\n",
        "test_question_sequences = pad_sequences(test_question_sequences, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AFBIf0OR-lU"
      },
      "outputs": [],
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "\n",
        "# Define the VGG16 model\n",
        "image_input = Input(shape=(224, 224, 3))\n",
        "cnn_model = VGG16(weights='imagenet', include_top=False, input_tensor=image_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cC3jwwTSl_O"
      },
      "outputs": [],
      "source": [
        "# Add a Global Average Pooling layer after the VGG16 model\n",
        "image_features = cnn_model.output\n",
        "image_features = GlobalAveragePooling2D()(image_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xm6jyLEnSo1I"
      },
      "outputs": [],
      "source": [
        "# Freeze the layers of the CNN model\n",
        "for layer in cnn_model.layers:\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xB0epOSHSsx-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbcb1432-be87-4cd1-f229-2c33f94f9414"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 3s 111ms/step\n",
            "31/31 [==============================] - 3s 110ms/step\n"
          ]
        }
      ],
      "source": [
        "# Extract image features\n",
        "train_image_features = cnn_model.predict(train_images)\n",
        "test_image_features = cnn_model.predict(test_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UK8BmS9TStmc"
      },
      "outputs": [],
      "source": [
        "# Define the LSTM model for processing questions\n",
        "question_input = Input(shape=(None,))\n",
        "embedding_layer = Embedding(vocab_size, 300, mask_zero=True)(question_input)\n",
        "lstm_layer = LSTM(256)(embedding_layer)\n",
        "\n",
        "# Combine image and question features\n",
        "combined_features = Concatenate()([image_features, lstm_layer])\n",
        "output = Dense(512, activation='relu')(combined_features)\n",
        "output = Dense(vocab_size, activation='softmax')(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JDkAEbLSv5N"
      },
      "outputs": [],
      "source": [
        "# Create the final model\n",
        "model = Model(inputs=[cnn_model.input, question_input], outputs=output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0WI7NC7S0OA"
      },
      "outputs": [],
      "source": [
        "image_label_mapping ={'বানর বার': 0, 'বসা': 1, 'না': 1, 'না': 2,'মল': 2, 'ঠিক': 3, 'সাদা': 3, 'হ্যাঁ': 4,'না': 5,'হ্যাঁ': 5,'বানর বার': 6, 'কুকুর': 7,'বাদামী': 7, 'বাদামী': 8, 'দুই': 9, 'চার': 10, 'পাঁচ': 11, 'সবুজ': 12, 'বাজানো': 13, 'বিড়াল': 14, 'নীল': 15, 'টেবিল': 16, 'ছেলে': 17, 'রৌদ্রোজ্জ্বল': 18, 'তিন': 19, 'কালো': 20, 'গাছ': 21, 'এক': 22, 'বেঞ্চ': 23, 'ধূসর': 24, 'হলুদ': 25, 'পাখি': 26, 'মেয়ে': 27, 'মদ': 28, 'মানুষ': 29, 'লাল': 30, 'বই': 31, 'হাড়': 32, 'সকার': 33, 'পাই': 34, 'লগ': 35, 'বেসবল': 36, 'ফুটবল': 37, 'কমলা': 38, 'পালঙ্ক': 39, 'দাঁড়িয়ে': 40, '0': 41, 'মহিলা': 42, 'খাবার': 43, 'মেঝে': 44, 'কাঠবিড়াল': 45, 'পাটি': 46, 'ঘুমাচ্ছেন': 47, 'আপেল': 48, 'বাইক': 49, 'উদ্ভিদ': 50, 'কম্বল': 51, 'ঘাস': 52, 'চেয়ার': 53, 'বাম': 54, 'কিছুই না': 55}\n",
        "label_mapping ={'বানর বার': 0, 'বসা': 1, 'না': 1, 'না': 2,'মল': 2, 'ঠিক': 3, 'সাদা': 3, 'হ্যাঁ': 4,'না': 5,'হ্যাঁ': 5,'বানর বার': 6, 'কুকুর': 7,'বাদামী': 7, 'বাদামী': 8, 'দুই': 9, 'চার': 10, 'পাঁচ': 11, 'সবুজ': 12, 'বাজানো': 13, 'বিড়াল': 14, 'নীল': 15, 'টেবিল': 16, 'ছেলে': 17, 'রৌদ্রোজ্জ্বল': 18, 'তিন': 19, 'কালো': 20, 'গাছ': 21, 'এক': 22, 'বেঞ্চ': 23, 'ধূসর': 24, 'হলুদ': 25, 'পাখি': 26, 'মেয়ে': 27, 'মদ': 28, 'মানুষ': 29, 'লাল': 30, 'বই': 31, 'হাড়': 32, 'সকার': 33, 'পাই': 34, 'লগ': 35, 'বেসবল': 36, 'ফুটবল': 37, 'কমলা': 38, 'পালঙ্ক': 39, 'দাঁড়িয়ে': 40, '0': 41, 'মহিলা': 42, 'খাবার': 43, 'মেঝে': 44, 'কাঠবিড়াল': 45, 'পাটি': 46, 'ঘুমাচ্ছেন': 47, 'আপেল': 48, 'বাইক': 49, 'উদ্ভিদ': 50, 'কম্বল': 51, 'ঘাস': 52, 'চেয়ার': 53, 'বাম': 54, 'কিছুই না': 55}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXRU0aGZS20O"
      },
      "outputs": [],
      "source": [
        "# Create label-encoded arrays for image and question answers\n",
        "train_image_labels = [image_label_mapping[label] for label in train_answers]\n",
        "train_image_labels = np.array(train_image_labels, dtype=np.int32)\n",
        "\n",
        "train_question_labels = [label_mapping[label] for label in train_answers]\n",
        "train_question_labels = np.array(train_question_labels, dtype=np.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cF_Afn5hS5Lk"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goBeDNEzmF5N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d59209b2-4937-4dac-edbc-f7ad40b26b6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "61/61 [==============================] - 12s 115ms/step - loss: 3.3056 - accuracy: 0.3186\n",
            "Epoch 2/25\n",
            "61/61 [==============================] - 4s 71ms/step - loss: 2.0783 - accuracy: 0.3873\n",
            "Epoch 3/25\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 1.7424 - accuracy: 0.4324\n",
            "Epoch 4/25\n",
            "61/61 [==============================] - 4s 69ms/step - loss: 1.5164 - accuracy: 0.4846\n",
            "Epoch 5/25\n",
            "61/61 [==============================] - 4s 69ms/step - loss: 1.3295 - accuracy: 0.5727\n",
            "Epoch 6/25\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 1.1239 - accuracy: 0.6547\n",
            "Epoch 7/25\n",
            "61/61 [==============================] - 4s 74ms/step - loss: 0.9819 - accuracy: 0.6967\n",
            "Epoch 8/25\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.8757 - accuracy: 0.7223\n",
            "Epoch 9/25\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.7285 - accuracy: 0.7561\n",
            "Epoch 10/25\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.6408 - accuracy: 0.7869\n",
            "Epoch 11/25\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.5788 - accuracy: 0.8074\n",
            "Epoch 12/25\n",
            "61/61 [==============================] - 4s 67ms/step - loss: 0.5063 - accuracy: 0.8432\n",
            "Epoch 13/25\n",
            "61/61 [==============================] - 4s 71ms/step - loss: 0.4254 - accuracy: 0.8566\n",
            "Epoch 14/25\n",
            "61/61 [==============================] - 4s 69ms/step - loss: 0.3699 - accuracy: 0.8699\n",
            "Epoch 15/25\n",
            "61/61 [==============================] - 4s 67ms/step - loss: 0.3141 - accuracy: 0.8934\n",
            "Epoch 16/25\n",
            "61/61 [==============================] - 4s 73ms/step - loss: 0.3077 - accuracy: 0.9057\n",
            "Epoch 17/25\n",
            "61/61 [==============================] - 4s 67ms/step - loss: 0.2270 - accuracy: 0.9252\n",
            "Epoch 18/25\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.2433 - accuracy: 0.9211\n",
            "Epoch 19/25\n",
            "61/61 [==============================] - 4s 69ms/step - loss: 0.1778 - accuracy: 0.9477\n",
            "Epoch 20/25\n",
            "61/61 [==============================] - 4s 71ms/step - loss: 0.1844 - accuracy: 0.9406\n",
            "Epoch 21/25\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.1844 - accuracy: 0.9416\n",
            "Epoch 22/25\n",
            "61/61 [==============================] - 4s 69ms/step - loss: 0.1271 - accuracy: 0.9549\n",
            "Epoch 23/25\n",
            "61/61 [==============================] - 4s 70ms/step - loss: 0.1062 - accuracy: 0.9631\n",
            "Epoch 24/25\n",
            "61/61 [==============================] - 4s 68ms/step - loss: 0.1004 - accuracy: 0.9621\n",
            "Epoch 25/25\n",
            "61/61 [==============================] - 4s 70ms/step - loss: 0.0965 - accuracy: 0.9682\n"
          ]
        }
      ],
      "source": [
        "history = model.fit([train_images, train_question_sequences], np.array(train_label_encoded), epochs=25, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glBXAPazsjxY"
      },
      "outputs": [],
      "source": [
        "# model.save(\"/content/drive/MyDrive/h5files/vgg16o.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/vgg16_model.h5')"
      ],
      "metadata": {
        "id": "tL0qLdYDuAC2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f225641b-16c4-4159-dc5f-82999013c351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "# Load the model\n",
        "loaded_model = keras.models.load_model('/content/drive/MyDrive/vgg16_model.h5')"
      ],
      "metadata": {
        "id": "UoXCzvC0uVmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O14SMk8zS8VE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "40e2b2c6-94b3-4a3f-af7e-9823ec5835c6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-5f666bcac1da>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_answers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'answer'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_label_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabel_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_answers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_label_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_label_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-5f666bcac1da>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_answers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'answer'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_label_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabel_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_answers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_label_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_label_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1090\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    393\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_indexing_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'answer'"
          ]
        }
      ],
      "source": [
        "test_answers = [item['answer'] for _, item in test_data.items()]\n",
        "\n",
        "test_label_encoded = [label_mapping[label] for label in test_answers]\n",
        "test_label_encoded = np.array(test_label_encoded, dtype=np.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ww8Z9C2S8Vq"
      },
      "outputs": [],
      "source": [
        "# # Evaluate the model on the test dataset\n",
        "# test_loss, test_accuracy = model.evaluate([test_images, test_question_sequences], test_label_encoded)\n",
        "\n",
        "# # Print the test accuracy\n",
        "# print(\"Test Accuracy:\", test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test dataset\n",
        "test_loss, test_accuracy = loaded_model.evaluate([test_images, test_question_sequences], test_label_encoded)\n",
        "\n",
        "# Print the test accuracy\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "id": "T83b8fF2ujou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k08vf9ZZS0EI"
      },
      "outputs": [],
      "source": [
        "# Provide an image and question\n",
        "input_image_path = '/content/drive/MyDrive/bangla dataset/Images/7.png'\n",
        "input_question = 'ছবিতে কোন প্রাণী আছে?'\n",
        "\n",
        "# Set the maximum sequence length\n",
        "max_question_length = 100\n",
        "\n",
        "# Preprocess the input image\n",
        "input_image = preprocess_image(input_image_path)\n",
        "input_image = np.expand_dims(input_image, axis=0)  # Add batch dimension\n",
        "\n",
        "# Tokenize and preprocess the input question\n",
        "input_question_sequence = tokenizer.texts_to_sequences([input_question])\n",
        "input_question_sequence = pad_sequences(input_question_sequence, maxlen=max_question_length)\n",
        "\n",
        "# Make prediction on the input\n",
        "prediction = loaded_model.predict([input_image, input_question_sequence])\n",
        "predicted_label = np.argmax(prediction)\n",
        "\n",
        "# Decode the predicted label\n",
        "label_mapping_reverse = {v: k for k, v in label_mapping.items()}\n",
        "predicted_answer = label_mapping_reverse[predicted_label]\n",
        "\n",
        "# Print the predicted answer\n",
        "print(\"Predicted Answer:\", predicted_answer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.layers import GlobalAveragePooling2D\n",
        "from PIL import Image\n",
        "\n",
        "# ... (rest of your code)\n",
        "\n",
        "# Load a pre-trained image classification model (e.g., ResNet50)\n",
        "image_classifier = ResNet50(weights='imagenet', include_top=True)\n",
        "\n",
        "# Define a threshold for image classification confidence\n",
        "image_classification_threshold = 0.5\n",
        "\n",
        "# Provide an image and question\n",
        "input_image_path = '/content/drive/MyDrive/bangla dataset/Images/2.png'\n",
        "input_question = 'কেউ কি সোফায় বসে আছে?'\n",
        "\n",
        "# Preprocess the input image\n",
        "input_image = preprocess_image(input_image_path)\n",
        "input_image = np.expand_dims(input_image, axis=0)  # Add batch dimension\n",
        "\n",
        "# Classify the input image using the image classification model\n",
        "image_classification_results = image_classifier.predict(input_image)\n",
        "image_confidence = np.max(image_classification_results)\n",
        "\n",
        "# Check if the image is valid and the question is not empty\n",
        "if image_confidence >= image_classification_threshold and input_question:\n",
        "    # Tokenize and preprocess the input question\n",
        "    input_question_sequence = tokenizer.texts_to_sequences([input_question])\n",
        "    input_question_sequence = pad_sequences(input_question_sequence, maxlen=max_question_length)\n",
        "\n",
        "    # Make prediction on the input\n",
        "    prediction = loaded_model.predict([input_image, input_question_sequence])\n",
        "    predicted_label = np.argmax(prediction)\n",
        "\n",
        "    # Decode the predicted label\n",
        "    label_mapping_reverse = {v: k for k, v in label_mapping.items()}\n",
        "    predicted_answer = label_mapping_reverse[predicted_label]\n",
        "\n",
        "    # Print the predicted answer\n",
        "    print(\"Predicted Answer:\", predicted_answer)\n",
        "else:\n",
        "    print(\"Invalid Input! Unable to predict.\")\n"
      ],
      "metadata": {
        "id": "RU5b8XXf3btI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3f37803-cfe0-4bb2-efda-727673c1281c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 67 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7ba41c2585e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 886ms/step\n",
            "Invalid Input! Unable to predict.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, GlobalAveragePooling2D\n",
        "from PIL import Image\n",
        "image_classifier = VGG16(weights='imagenet', include_top=True)\n",
        "\n",
        "# Define a threshold for image classification confidence\n",
        "image_classification_threshold = 0.5\n",
        "# Provide an image and question\n",
        "input_image_path = '/content/drive/MyDrive/bangla dataset/Images/7.png'\n",
        "input_question = 'ছবিতে কোন প্রাণী আছে?'\n",
        "\n",
        "# Preprocess the input image\n",
        "input_image = preprocess_image(input_image_path)\n",
        "input_image = np.expand_dims(input_image, axis=0)  # Add batch dimension\n",
        "\n",
        "# Classify the input image using the image classification model\n",
        "image_classification_results = image_classifier.predict(input_image)\n",
        "image_confidence = np.max(image_classification_results)\n",
        "\n",
        "# Check if the image is valid and the question is not empty\n",
        "if image_confidence >= image_classification_threshold and input_question:\n",
        "    # Tokenize and preprocess the input question\n",
        "    input_question_sequence = tokenizer.texts_to_sequences([input_question])\n",
        "    input_question_sequence = pad_sequences(input_question_sequence, maxlen=max_question_length)\n",
        "\n",
        "    # Iterate through training images and compare features\n",
        "    matching_image_id = None\n",
        "    for i, train_image_feature in enumerate(train_image_features):\n",
        "        # Compare image features\n",
        "        feature_distance = np.linalg.norm(train_image_feature - image_features)\n",
        "\n",
        "        # Set a threshold for similarity\n",
        "        feature_threshold = 0.2  # You can adjust this threshold\n",
        "\n",
        "        if feature_distance < feature_threshold:\n",
        "            matching_image_id = i\n",
        "            break\n",
        "\n",
        "    if matching_image_id is not None:\n",
        "        # Now that a matching image is found, extract the image feature\n",
        "        matching_image_feature = train_image_features[matching_image_id]\n",
        "\n",
        "        # Predict the answer based on the input question\n",
        "        prediction = loaded_model.predict([train_images[matching_image_id:matching_image_id + 1], input_question_sequence])\n",
        "        predicted_label = np.argmax(prediction)\n",
        "\n",
        "        # Decode the predicted label\n",
        "        label_mapping_reverse = {v: k for k, v in label_mapping.items()}\n",
        "        predicted_answer = label_mapping_reverse[predicted_label]\n",
        "\n",
        "        # Check if the input question feature and predicted question feature match\n",
        "        question_feature_distance = np.linalg.norm(matching_image_feature - matching_image_feature)\n",
        "\n",
        "        if question_feature_distance < 0.1:\n",
        "            print(\"Predicted Answer:\", predicted_answer)\n",
        "            # You can also perform additional processing on the matching image as needed\n",
        "            matching_image_path = train_image_ids[matching_image_id]\n",
        "            # Load and process the matching image, e.g., matching_image = preprocess_image(matching_image_path)\n",
        "        else:\n",
        "            print(\"Input wrong question for the image.\")\n",
        "    else:\n",
        "        print(\"Input wrong image.\")\n",
        "else:\n",
        "    print(\"Invalid Input! Unable to predict.\")\n"
      ],
      "metadata": {
        "id": "q64trJ9VAfhV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "388dae0f-2500-424d-d52d-9e4f8705e544"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 142ms/step\n",
            "Invalid Input! Unable to predict.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tSCEwAjbAfkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fSPtJChzAfmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hXEj3QXY3bwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QwQF1igq3b2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hes_ciT6TBKA"
      },
      "outputs": [],
      "source": [
        "# Provide an image and question\n",
        "input_image_path = '/content/drive/MyDrive/bangla dataset/Images/2.png'\n",
        "input_question = 'কেউ কি সোফায় বসে আছে?'\n",
        "\n",
        "# Set the maximum sequence length\n",
        "max_question_length = 100\n",
        "\n",
        "# Preprocess the input image\n",
        "input_image = preprocess_image(input_image_path)\n",
        "input_image = np.expand_dims(input_image, axis=0)  # Add batch dimension\n",
        "\n",
        "# Tokenize and preprocess the input question\n",
        "input_question_sequence = tokenizer.texts_to_sequences([input_question])\n",
        "input_question_sequence = pad_sequences(input_question_sequence, maxlen=max_question_length)\n",
        "\n",
        "# Make prediction on the input\n",
        "prediction = model.predict([input_image, input_question_sequence])\n",
        "predicted_label = np.argmax(prediction)\n",
        "\n",
        "# Decode the predicted label\n",
        "label_mapping_reverse = {v: k for k, v in label_mapping.items()}\n",
        "predicted_answer = label_mapping_reverse[predicted_label]\n",
        "\n",
        "# Print the predicted answer\n",
        "print(\"Predicted Answer:\", predicted_answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"/content/drive/MyDrive/h5files/vgg16f.h5\")"
      ],
      "metadata": {
        "id": "_RdpYq7FkInF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Assuming you have a function preprocess_image() and a tokenizer\n",
        "# Also, you need to define the label_mapping dictionary and the model\n",
        "# Function to check if a string is empty or consists of only spaces\n",
        "def is_empty_or_spaces(s):\n",
        "    return s.strip() == \"\"\n",
        "input_image_path = input(\"Enter image path: \").strip()\n",
        "input_question = input(\"Enter question: \").strip()\n",
        "\n",
        "# Check if either image path or question is empty\n",
        "if is_empty_or_spaces(input_image_path) and is_empty_or_spaces(input_question):\n",
        "    print(\"Please enter an image path or a question.\")\n",
        "else:\n",
        "    # Set the maximum sequence length\n",
        "    max_question_length = 100\n",
        "\n",
        "    # Preprocess the input image if not empty\n",
        "    input_image = None\n",
        "    if not is_empty_or_spaces(input_image_path):\n",
        "        input_image = preprocess_image(input_image_path)\n",
        "        input_image = np.expand_dims(input_image, axis=0)  # Add batch dimension\n",
        "\n",
        "    # Tokenize and preprocess the input question if not empty\n",
        "    input_question_sequence = None\n",
        "    if not is_empty_or_spaces(input_question):\n",
        "        input_question_sequence = tokenizer.texts_to_sequences([input_question])\n",
        "        input_question_sequence = pad_sequences(input_question_sequence, maxlen=max_question_length)\n",
        "\n",
        "    if input_image is not None and input_question_sequence is not None:\n",
        "        # Make prediction on the input\n",
        "        prediction = model.predict([input_image, input_question_sequence])\n",
        "        predicted_label = np.argmax(prediction)\n",
        "\n",
        "        # Decode the predicted label\n",
        "        label_mapping_reverse = {v: k for k, v in label_mapping.items()}\n",
        "        predicted_answer = label_mapping_reverse[predicted_label]\n",
        "\n",
        "        # Print the predicted answer\n",
        "        print(\"Predicted Answer:\", predicted_answer)\n",
        "    else:\n",
        "        print(\"Please provide either an image or a question.\")"
      ],
      "metadata": {
        "id": "xKI6uD2Wp44M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "voLdPEn6p48m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ab55eRMCp5E4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}